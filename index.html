<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Tanmoy Das | Portfolio</title>
  <!-- KaTeX for math rendering -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
      onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true}, {left: '\\(', right: '\\)', display: false}]});">
  </script>
  <!-- Tailwind CSS CDN -->
  <script src="https://cdn.tailwindcss.com"></script>
  <!-- Lucide Icons CDN -->
  <script src="https://unpkg.com/lucide@latest"></script>
  <!-- Google Fonts (Inter) -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;900&display=swap" rel="stylesheet">
  <meta name="description" content="Portfolio website for Tanmoy Das, Computer Vision and Machine Learning Researcher."/>
  <link rel="icon" href="me.jpg"/>
  <style>
    body { font-family: 'Inter', sans-serif; }
    .fade-in { opacity: 0; transform: translateY(30px); transition: all 1s cubic-bezier(.4,0,.2,1); }
    .fade-in.visible { opacity: 1; transform: translateY(0); }
    ::selection { background: #22d3ee44; }
    ::-webkit-scrollbar { width: 8px; background: #18181b; }
    ::-webkit-scrollbar-thumb { background: #22d3ee88; border-radius: 8px; }
    .dropdown:not(:hover):not(.open) .dropdown-menu { display: none; }
    @keyframes skill-pop {
      from { opacity: 0; transform: translateY(20px) scale(0.97);}
      to   { opacity: 1; transform: translateY(0) scale(1);}
    }
    #skills-list .animate-in {
      opacity: 1 !important;
      transform: translateY(0) scale(1) !important;
    }
    /* --- Slicky blobs background --- */
    .blob-bg { position: fixed; inset: 0; z-index: -10; overflow: hidden; pointer-events: none;}
    .blob-bg div { position: absolute; border-radius: 9999px; filter: blur(60px); }
    .blob1 { width:400px; height:400px; background:#22d3ee; opacity:0.24; left:-100px; top:-100px; animation: blob1 16s ease-in-out infinite alternate;}
    .blob2 { width:350px; height:350px; background:#6366f1; opacity:0.20; right:-80px; top:160px; animation: blob2 20s ease-in-out infinite alternate;}
    .blob3 { width:320px; height:320px; background:#f472b6; opacity:0.19; left:40vw; top:65vh; animation: blob3 22s ease-in-out infinite alternate;}
    @keyframes blob1 {0%,100%{transform:translate(0,0) scale(1);}50%{transform:translate(40px,60px) scale(1.13);}}
    @keyframes blob2 {0%,100%{transform:translate(0,0) scale(1);}50%{transform:translate(-30px,40px) scale(1.09);}}
    @keyframes blob3 {0%,100%{transform:translate(0,0) scale(1);}50%{transform:translate(30px,-40px) scale(1.12);}}
  </style>
</head>

<body class="bg-gray-950 text-gray-100 font-sans">
  <!-- Animated Slicky Blobs Background -->
  <div class="blob-bg">
    <div class="blob1"></div>
    <div class="blob2"></div>
    <div class="blob3"></div>
  </div>
  <!-- Background ASCII Canvas -->
<canvas id="codeRain" class="fixed inset-0 w-full h-full -z-10 pointer-events-none"></canvas>
<!-- Transparent overlay for click detection -->
<div id="codeRainClick" class="fixed inset-0 w-full h-full -z-10" style="background:transparent;cursor:pointer"></div>
  <!-- NAVIGATION BAR -->
  <nav class="sticky top-0 z-50 bg-gray-950/80 backdrop-blur flex items-center justify-between px-6 py-3 border-b border-gray-800 mb-2">
    <div class="font-bold text-xl text-cyan-400 tracking-wide">Tanmoy Das</div>
    <ul class="flex items-center gap-4">
      <li><a href="#about" class="hover:text-cyan-400 transition">About</a></li>
      <li><a href="#education" class="hover:text-cyan-400 transition">Education</a></li>
      <li><a href="#experience" class="hover:text-cyan-400 transition">Experience</a></li>
      <li><a href="#projects" class="hover:text-cyan-400 transition">Projects</a></li>
      <li><a href="#skills" class="hover:text-cyan-400 transition">Skills</a></li>
      <!-- Blog Dropdown -->
      <li class="relative dropdown">
        <button id="blogMenuBtn" class="hover:text-cyan-400 transition flex items-center gap-1 focus:outline-none">
          Blog
          <svg class="w-4 h-4 ml-1" fill="none" stroke="currentColor" stroke-width="2" viewBox="0 0 24 24">
            <path stroke-linecap="round" stroke-linejoin="round" d="M19 9l-7 7-7-7"/>
          </svg>
        </button>
        <ul id="blogDropdown" class="dropdown-menu absolute right-0 mt-2 min-w-[230px] bg-gray-900 border border-gray-800 rounded-xl shadow-xl py-2 z-40 hidden">
          <!-- Blog links will be inserted here by JS -->
        </ul>
      </li>
    </ul>
  </nav>

  <!-- HEADER/HERO -->
  <header class="pt-8 pb-5 text-center fade-in">
    <img src="me.jpg" alt="Tanmoy Das" class="mx-auto w-40 h-40 rounded-full mb-6 border-4 border-gray-800 shadow-2xl"/>
    <h1 class="text-4xl font-black tracking-tight mb-1">Tanmoy Das</h1>
    <p class="text-lg text-cyan-400 mb-3 font-semibold">Computer Vision & Deep Learning Researcher</p>
    <div class="flex justify-center gap-5 mt-3">
      <a href="https://github.com/tammy3107" target="_blank" aria-label="GitHub" class="hover:text-cyan-400"><i data-lucide="github" class="w-6 h-6"></i></a>
      <a href="https://www.linkedin.com/in/tanmoy-das-15926014a/" target="_blank" aria-label="LinkedIn" class="hover:text-cyan-400"><i data-lucide="linkedin" class="w-6 h-6"></i></a>
      <a href="mailto:tanmoydas202231@gmail.com" aria-label="Email" class="hover:text-cyan-400"><i data-lucide="mail" class="w-6 h-6"></i></a>
    </div>
    <div class="text-gray-400 text-sm mt-2">Bonn, Germany | +49 1573 9675110</div>
  </header>

  <!-- About -->
  <section id="about" class="fade-in container mx-auto max-w-3xl mb-12 px-6 scroll-mt-20">
    <div class="flex items-center gap-3 mb-4">
      <i data-lucide="user" class="w-7 h-7 text-cyan-400"></i>
      <h2 class="text-2xl font-bold text-cyan-400">About Me</h2>
    </div>
    <div class="bg-gray-900 rounded-2xl shadow-xl p-8 border border-gray-800 text-base text-gray-200">
      Passionate researcher in computer vision and deep learning, with a strong foundation in mathematics and computer science. Experienced in designing and optimizing advanced neural architectures for medical imaging, NLP, and generative modeling. Driven by curiosity and innovation, I aim to contribute to cutting-edge research in image analysis, representation learning, and computational modeling.
    </div>
  </section>

  <!-- Education -->
<section id="education" class="fade-in container mx-auto max-w-3xl mb-12 px-6 scroll-mt-20">
  
  <div class="flex items-center gap-3 mb-4">
    <i data-lucide="graduation-cap" class="w-7 h-7 text-cyan-400"></i>
    <h2 class="text-2xl font-bold text-cyan-400">Education</h2>
  </div>
  <div class="bg-gray-900 rounded-2xl shadow-xl p-8 border border-gray-800 space-y-8">
    <!-- University of Bonn -->
    <div class="flex flex-col md:flex-row items-center gap-6">
      <img src="logos/UNI_Bonn_Logo_Kompakt.jpg" 
        alt="University of Bonn" class="w-28 h-28 rounded-xl object-contain bg-white p-2 shadow-lg border border-gray-700" />
      <div class="flex-1 text-left">
        <div class="font-bold text-lg">MSc, Computer Science</div>
        <div class="text-sm text-gray-400 mb-1">University of Bonn, Germany | 2021–2025</div>
        <div class="text-sm mb-1">Major: Computer Vision & AI</div>
        <div class="text-sm mb-1">Thesis: 3D Nonwoven Structure Segmentation & Generation</div>
        <div class="text-sm mb-1">Thesis Grade: 1.6/4</div>
      </div>
    </div>

    <!-- SRM Institute -->
    <div class="flex flex-col md:flex-row items-center gap-6">
      <img src="logos/srm.webp"
        alt="SRM Institute" class="w-28 h-28 rounded-xl object-contain bg-white p-2 shadow-lg border border-gray-700" />
      <div class="flex-1 text-left">
        <div class="font-bold text-lg">B.Tech, Computer Science</div>
        <div class="text-sm text-gray-400 mb-1">SRM Institute, India | 2016–2020</div>
        <div class="text-sm mb-1">Grade: 7.42/10</div>
      </div>
    </div>

    <!-- Nalanda Academy -->
    <div class="flex flex-col md:flex-row items-center gap-6">
      <img src="logos/nalanda.png" 
        alt="Nalanda Academy" class="w-28 h-28 rounded-xl object-contain bg-white p-2 shadow-lg border border-gray-700" />
      <div class="flex-1 text-left">
        <div class="font-bold text-lg">Higher Secondary (PCM)</div>
        <div class="text-sm text-gray-400 mb-1">Nalanda Academy, Rajasthan, India | 2016</div>
        <div class="text-sm mb-1">Grade: 80.4%</div>
      </div>
    </div>

  </div>
</section>


 <!-- Experience -->
<section id="experience" class="fade-in container mx-auto max-w-3xl mb-12 px-6 scroll-mt-20">
  <div class="flex items-center gap-3 mb-4">
      <i data-lucide="briefcase" class="w-7 h-7 text-cyan-400"></i>
      <h2 class="text-2xl font-bold text-cyan-400">Experience</h2>
  </div>
  <div class="bg-gray-900 rounded-2xl shadow-xl p-8 border border-gray-800 space-y-8">

    <!-- Procter & Gamble -->
    <div class="flex flex-col md:flex-row items-center gap-6">
      <img src="logos/Procter_%26_Gamble_logo.svg.png"
        alt="Procter & Gamble Logo" class="w-28 h-28 rounded-xl object-contain bg-white p-3 shadow-lg border border-gray-700" />
      <div class="flex-1 text-left">
        <div class="font-bold text-lg">Procter & Gamble (P&G), Germany</div>
        <div class="text-sm text-gray-400 mb-1">Intern | Apr 2023 – Sep 2024</div>
        <ul class="list-disc list-inside text-sm mt-1 ml-2 text-gray-200">
          <li>Master’s Thesis on 3D UNet, Diffusion & Generative Models for CT image generation.</li>
          <li>Optimized Attention Mechanisms for UNet; improved IoU by 33.3%.</li>
          <li>Developed a custom LLM (RAG-based), deployed with Streamlit.</li>
          <li>Collaborated with cross-functional teams to enhance workflows.</li>
        </ul>
      </div>
    </div>

    <!-- Phenorob -->
    <div class="flex flex-col md:flex-row items-center gap-6">
      <img src="logos/phenorob.png"
        alt="Phenorob Logo" class="w-28 h-28 rounded-xl object-contain bg-white p-3 shadow-lg border border-gray-700" />
      <div class="flex-1 text-left">
        <div class="font-bold text-lg">Phenorob, Bonn, Germany</div>
        <div class="text-sm text-gray-400 mb-1">Student Assistant | Oct 2022 – Mar 2023</div>
        <ul class="list-disc list-inside text-sm mt-1 ml-2 text-gray-200">
          <li>Built deep learning models for honeybee/bumblebee classification.</li>
          <li>Managed datasets; optimized workflows; processed satellite images with U-Net models.</li>
          <li>Supported PhD students with academic and admin procedures.</li>
        </ul>
      </div>
    </div>

  </div>
</section>


  <!-- Projects -->
  <section id="projects" class="fade-in container mx-auto max-w-3xl mb-12 px-6 scroll-mt-20">
    <div class="flex items-center gap-3 mb-4">
      <i data-lucide="code" class="w-7 h-7 text-cyan-400"></i>
      <h2 class="text-2xl font-bold text-cyan-400">Personal Projects</h2>
    </div>
    <div class="bg-gray-900 rounded-2xl shadow-xl p-8 border border-gray-800 space-y-6">
      <div>
        <div class="font-semibold">Depth Estimation from Thermal Images</div>
        <p class="text-xs mb-1">Monocular depth estimation using transformer-based DUST3R with dual-branch encoder-decoder.</p>
        <a href="https://github.com/tammy3107/Lab-project-ws2425" class="underline text-sm hover:text-cyan-400" target="_blank">View on GitHub</a>
      </div>
      <div>
        <div class="font-semibold">CycleGAN Implementation</div>
        <p class="text-xs mb-1">CycleGAN in PyTorch for summer-winter image translation. Explored loss functions.</p>
        <a href="https://github.com/tammy3107/Cycle_GAN" class="underline text-sm hover:text-cyan-400" target="_blank">View on GitHub</a>
      </div>
      <div>
        <div class="font-semibold">English-German Translator</div>
        <p class="text-xs mb-1">Seq2seq + attention translation model, custom tokenization & vocabulary. Strong results.</p>
        <a href="https://github.com/tammy3107/English-to-German-translator" class="underline text-sm hover:text-cyan-400" target="_blank">View on GitHub</a>
      </div>
    </div>
  </section>

  <!-- SKILLS with animated icons -->
  <section id="skills" class="fade-in container mx-auto max-w-3xl mb-12 px-6 scroll-mt-20">
    <div class="flex items-center gap-3 mb-4">
      <i data-lucide="star" class="w-7 h-7 text-cyan-400"></i>
      <h2 class="text-2xl font-bold text-cyan-400">Skills</h2>
    </div>
    <div id="skills-list" class="grid grid-cols-2 sm:grid-cols-3 md:grid-cols-4 gap-8 pt-6">
      <!-- Skill cards injected by JS -->
    </div>
  </section>

  <!-- Blog Section -->
  <section id="blog" class="fade-in container mx-auto max-w-3xl mb-16 px-6 scroll-mt-20">
    <div class="flex items-center gap-3 mb-4">
      <i data-lucide="pen-line" class="w-7 h-7 text-cyan-400"></i>
      <h2 class="text-2xl font-bold text-cyan-400">Blog</h2>
    </div>
    <article id="blog1" data-title="How I Built This Portfolio Website" class="bg-gray-900 rounded-2xl shadow-xl p-8 border border-gray-800 mb-9 scroll-mt-24">
      <h3 class="text-lg font-semibold mb-1">How I Built This Portfolio Website</h3>
      <div class="text-xs text-gray-400 mb-2">Published: 29 May 2025</div>
      <p class="text-sm text-gray-200 mb-2">
        Building this portfolio website was a fun blend of design, programming, and a little bit of game logic! My goal was to create a modern, interactive, and professional online presence that showcases not only my work, but my personality as a coder.
      </p>
      <ul class="list-disc ml-5 text-sm text-gray-200 mb-2">
        <li>
          <b>Framework-free, super fast:</b> I wrote the site using just HTML5, Tailwind CSS (for rapid modern styling), and a few lines of JavaScript—no React, no heavy build tools, so everything loads fast.
        </li>
        <li>
          <b>Modern layout:</b> I used a single-column layout with clear cards for each section. The profile picture, project and education/experience cards, and blog section are all mobile-friendly and fully responsive.
        </li>
        <li>
          <b>Animated skills:</b> Each of my technical skills is shown as an icon that pops in with animation—this is done using Lucide icons and JavaScript for a bit of “wow” effect.
        </li>
        <li>
          <b>ASCII background effects:</b> The animated background is pure HTML5 canvas—featuring multiple ASCII art effects (like code rain and waves), and you can switch between them by clicking the background. This is all custom-coded to match the coder vibe!
        </li>
        <li>
          <b>Dynamic blog:</b> My blog section is fully integrated, and the dropdown menu at the top smoothly scrolls you to any post. Adding a new blog entry is as easy as pasting in a new block of HTML.
        </li>
        <li>
          <b>Open source and easy to expand:</b> The whole site is hosted on GitHub Pages. If I want to add new features, projects, or sections, I can just update the code and push—no deployment hassles.
        </li>
      </ul>
      <p class="text-sm text-gray-200 mb-2">
        <b>Key tech stack:</b>  
        Tailwind CSS, Lucide Icons, HTML5 Canvas (for backgrounds), and a sprinkle of vanilla JavaScript for the animated effects and navigation.
      </p>
      <p class="text-sm text-gray-200 mb-2">
        <b>Why code this from scratch?</b><br>
        I wanted full creative control and to demonstrate my programming and design skills directly in my own website, rather than relying on templates. It was also a great exercise in rapid prototyping and UI/UX thinking!
      </p>
      <p class="text-sm text-gray-200">
        If you have questions about how I built any part of this site, or want tips for building your own, feel free to reach out!
      </p>
    </article>
    <article id="blog2" data-title="Understanding Diffusion Models (An Extensive Guide)" class="bg-gray-900 rounded-2xl shadow-xl p-8 border border-gray-800 mb-9 scroll-mt-24">
      <h3 class="text-lg font-semibold mb-1">Understanding Diffusion Models (An Extensive Guide)</h3>
      <div class="text-xs text-gray-400 mb-2">Published: 3 June 2025</div>
      <p class="text-sm text-gray-200 mb-2">
        <b>Diffusion models</b> have quickly become the state-of-the-art for generative modeling, powering much of the excitement around AI art, text-to-image synthesis, and even scientific data simulation. If you’re curious about how these models work (and how they differ from earlier techniques like GANs), this post is for you!
      </p>
      <h4 class="font-semibold text-cyan-400 mt-4 mb-1">What Are Diffusion Models?</h4>
      <p class="text-sm text-gray-200 mb-2">
        At a high level, a diffusion model is a generative model that learns to reverse a gradual noising process. The model is trained to transform random noise into realistic samples (images, audio, etc.), step by step, by learning how to “denoise” at each stage.
      </p>
      <ul class="list-disc ml-5 text-sm text-gray-200 mb-2">
        <li>
          The <b>forward process</b>: Start with real data and add small amounts of random noise in many steps, until the data becomes pure noise.
        </li>
        <li>
          The <b>reverse process</b>: Train a neural network to predict and remove this noise, gradually reconstructing data from noise.
        </li>
        <li>
          This process is mathematically inspired by ideas from non-equilibrium thermodynamics and Markov chains.
        </li>
      </ul>
      <h4 class="font-semibold text-cyan-400 mt-4 mb-1">How Do They Compare to GANs?</h4>
      <p class="text-sm text-gray-200 mb-2">
        GANs (Generative Adversarial Networks) pit two networks against each other: a generator and a discriminator. They’re powerful, but can be unstable and prone to mode collapse (generating limited diversity). Diffusion models, on the other hand:
      </p>
      <ul class="list-disc ml-5 text-sm text-gray-200 mb-2">
        <li>Are more stable to train—no adversarial “game.”</li>
        <li>Allow for more control over the sampling process (e.g., conditional image generation).</li>
        <li>Often produce crisper, more detailed outputs, especially in high-res scenarios.</li>
        <li>Can be slower at inference (though new sampling techniques are closing this gap).</li>
      </ul>
      <h4 class="font-semibold text-cyan-400 mt-4 mb-1">The Core Mathematics (Briefly)</h4>
      <p class="text-sm text-gray-200 mb-2">
        The model learns to approximate the probability distribution of the data via a sequence of conditional distributions. During training, noise is gradually added to data; at each timestep, the model predicts either the clean data or the noise, given the current noisy sample.
      </p>
      <ul class="list-disc ml-5 text-sm text-gray-200 mb-2">
        <li>
          <b>Forward diffusion:</b> <span>$$x_t = \sqrt{\alpha_t} x_0 + \sqrt{1 - \alpha_t} \, \epsilon$$</span>, where <b>\(x_0\)</b> is real data, <b>\(\epsilon\)</b> is Gaussian noise, and <b>\(\alpha_t\)</b> controls noise schedule.
        </li>
        <li>
          <b>Reverse denoising:</b> The model predicts <b>\(\epsilon\)</b> (or <b>\(x_0\)</b>), using a neural network at each timestep <b>\(t\)</b>.
        </li>
      </ul>
      <h4 class="font-semibold text-cyan-400 mt-4 mb-1">Applications</h4>
      <ul class="list-disc ml-5 text-sm text-gray-200 mb-2">
        <li>
          <b>Image generation:</b> Stable Diffusion, DALL·E 2, Imagen.
        </li>
        <li>
          <b>Audio synthesis:</b> Speech and music generation (e.g., DiffWave).
        </li>
        <li>
          <b>Data simulation:</b> Simulating scientific or physical data, 3D molecules, medical images, etc.
        </li>
        <li>
          <b>Conditional/controlled generation:</b> Generate images from text, sketches, or other signals.
        </li>
      </ul>
      <h4 class="font-semibold text-cyan-400 mt-4 mb-1">Recent Trends & Tips for Researchers</h4>
      <ul class="list-disc ml-5 text-sm text-gray-200 mb-2">
        <li>Look for improvements in <b>sampling speed</b> (e.g., DDIM, DPM-Solver, and others).</li>
        <li>Architecture choices matter: <b>UNet-like</b> structures are very popular for diffusion models in vision.</li>
        <li>Pay attention to the <b>noise schedule</b>—different choices affect output diversity and quality.</li>
        <li>Combining diffusion models with other AI techniques (transformers, GANs, autoencoders) is a hot area.</li>
      </ul>
      <h4 class="font-semibold text-cyan-400 mt-4 mb-1">Further Reading</h4>
      <ul class="list-disc ml-5 text-sm text-gray-200 mb-2">
        <li>
          <a href="https://arxiv.org/abs/2006.11239" target="_blank" class="underline hover:text-cyan-400">Denoising Diffusion Probabilistic Models (DDPM)</a> — the foundational paper
        </li>
        <li>
          <a href="https://stability.ai/blog/stable-diffusion-announcement" target="_blank" class="underline hover:text-cyan-400">Stable Diffusion: How it works</a>
        </li>
        <li>
          <a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/" target="_blank" class="underline hover:text-cyan-400">Lilian Weng’s blog: Diffusion Models</a>
        </li>
        <li>
          <a href="https://github.com/huggingface/diffusers" target="_blank" class="underline hover:text-cyan-400">Hugging Face Diffusers Library</a>
        </li>
      </ul>
      <p class="text-sm text-gray-200">
        Have more questions, or want to see my own diffusion model projects?  
        <a href="mailto:tanmoydas202231@gmail.com" class="underline hover:text-cyan-400">Drop me an email!</a>
      </p>
    </article>
    <article id="blog3" data-title="GAN vs VAE vs Diffusion Models: A Modern Comparison" class="bg-gray-900 rounded-2xl shadow-xl p-8 border border-gray-800 mb-9 scroll-mt-24">
      <h3 class="text-lg font-semibold mb-1">GAN vs VAE vs Diffusion Models: A Modern Comparison</h3>
      <div class="text-xs text-gray-400 mb-2">Published: 8 June 2025</div>
      
      <p class="text-sm text-gray-200 mb-2">
        <b>Generative models</b> have revolutionized the way we create images, audio, and even text with artificial intelligence. The three most prominent families today are <b>GANs</b> (Generative Adversarial Networks), <b>VAEs</b> (Variational Autoencoders), and <b>Diffusion Models</b>. This post offers a side-by-side look at their approaches, strengths, and where you might use each.
      </p>
    
      <h4 class="font-semibold text-cyan-400 mt-4 mb-1">GANs: Generative Adversarial Networks</h4>
      <p class="text-sm text-gray-200 mb-2">
        <b>GANs</b> use a “game” between two networks: a <b>generator</b> that tries to make fake data look real, and a <b>discriminator</b> that tries to tell fake from real. Over time, the generator learns to produce remarkably realistic samples.
      </p>
      <ul class="list-disc ml-5 text-sm text-gray-200 mb-2">
        <li><b>Strengths:</b> Can create highly sharp, high-resolution images; widely used for photorealistic art and deepfakes.</li>
        <li><b>Weaknesses:</b> Training can be unstable (mode collapse, vanishing gradients); sometimes lacks diversity.</li>
        <li><b>Notable use cases:</b> DeepFake, StyleGAN, super-resolution, image-to-image translation (pix2pix, CycleGAN).</li>
      </ul>
    
      <h4 class="font-semibold text-cyan-400 mt-4 mb-1">VAEs: Variational Autoencoders</h4>
      <p class="text-sm text-gray-200 mb-2">
        <b>VAEs</b> encode data into a lower-dimensional <b>latent space</b> and decode back to samples, using probability to encourage smoothness and variation. They optimize both how well they reconstruct data and how close the latent space matches a normal distribution.
      </p>
      <ul class="list-disc ml-5 text-sm text-gray-200 mb-2">
        <li><b>Strengths:</b> Stable, easy to train, provides explicit latent variables for control, interpolation, and clustering.</li>
        <li><b>Weaknesses:</b> Output can be blurry compared to GANs or diffusion; less suited for ultra-high-res images.</li>
        <li><b>Notable use cases:</b> Representation learning, anomaly detection, controllable generation, semi-supervised learning.</li>
      </ul>
    
      <h4 class="font-semibold text-cyan-400 mt-4 mb-1">Diffusion Models</h4>
      <p class="text-sm text-gray-200 mb-2">
        <b>Diffusion models</b> start with pure noise and iteratively “denoise” it, learning to reverse a random noising process. They excel at high-fidelity, diverse samples and have become the go-to method for text-to-image generation.
      </p>
      <ul class="list-disc ml-5 text-sm text-gray-200 mb-2">
        <li><b>Strengths:</b> Extremely high-quality outputs, stable training, flexible (can be conditioned on text, etc.).</li>
        <li><b>Weaknesses:</b> Traditionally slow to sample (many steps), but new fast samplers help.</li>
        <li><b>Notable use cases:</b> DALL·E 2, Stable Diffusion, Imagen, molecular and scientific simulation.</li>
      </ul>
    
      <h4 class="font-semibold text-cyan-400 mt-4 mb-1">Side-by-Side Comparison</h4>
      <table class="w-full text-xs text-gray-200 mb-4 border-collapse">
        <thead>
          <tr>
            <th class="border-b border-gray-700 py-2 text-left">Model</th>
            <th class="border-b border-gray-700 py-2 text-left">Core Idea</th>
            <th class="border-b border-gray-700 py-2 text-left">Strengths</th>
            <th class="border-b border-gray-700 py-2 text-left">Weaknesses</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td class="py-2">GAN</td>
            <td>Adversarial training (generator vs. discriminator)</td>
            <td>Sharp, realistic samples</td>
            <td>Unstable, mode collapse</td>
          </tr>
          <tr>
            <td class="py-2">VAE</td>
            <td>Probabilistic encoding/decoding</td>
            <td>Stable, interpretable latent space</td>
            <td>Blurry outputs</td>
          </tr>
          <tr>
            <td class="py-2">Diffusion</td>
            <td>Iterative denoising</td>
            <td>Best fidelity, flexible</td>
            <td>Slow sampling (improving!)</td>
          </tr>
        </tbody>
      </table>
    
      <h4 class="font-semibold text-cyan-400 mt-4 mb-1">Mathematical Glimpse</h4>
      <ul class="list-disc ml-5 text-sm text-gray-200 mb-2">
        <li>
          <b>GAN loss:</b> <span>$$
          \min_G \max_D \mathbb{E}_{x \sim p_\text{data}} [\log D(x)] + \mathbb{E}_{z \sim p(z)} [\log (1-D(G(z)))]
          $$</span>
        </li>
        <li>
          <b>VAE loss:</b> <span>$$
          \mathcal{L}_\text{VAE} = \mathbb{E}_{q(z|x)}[\log p(x|z)] - \text{KL}(q(z|x)\,\|\,p(z))
          $$</span>
        </li>
        <li>
          <b>Diffusion step:</b> <span>$$x_t = \sqrt{\alpha_t} x_0 + \sqrt{1 - \alpha_t}\,\epsilon$$</span>
        </li>
      </ul>
    
      <h4 class="font-semibold text-cyan-400 mt-4 mb-1">Which Should I Use?</h4>
      <p class="text-sm text-gray-200 mb-2">
        <b>GANs</b> are great for tasks demanding photorealism and when you can manage training tricks. <b>VAEs</b> are fantastic for learning interpretable representations and unsupervised learning. <b>Diffusion models</b> are now preferred for the highest-quality, most flexible generation—especially for images and cross-modal tasks.
      </p>
    
      <h4 class="font-semibold text-cyan-400 mt-4 mb-1">Further Reading</h4>
      <ul class="list-disc ml-5 text-sm text-gray-200 mb-2">
        <li>
          <a href="https://arxiv.org/abs/1406.2661" target="_blank" class="underline hover:text-cyan-400">GANs: Goodfellow et al. (2014)</a>
        </li>
        <li>
          <a href="https://arxiv.org/abs/1312.6114" target="_blank" class="underline hover:text-cyan-400">VAEs: Kingma & Welling (2013)</a>
        </li>
        <li>
          <a href="https://arxiv.org/abs/2006.11239" target="_blank" class="underline hover:text-cyan-400">Diffusion Models: Ho et al. (2020)</a>
        </li>
      </ul>
      <p class="text-sm text-gray-200">
        Still unsure? <a href="mailto:tanmoydas202231@gmail.com" class="underline hover:text-cyan-400">Let’s discuss!</a>
      </p>
   </article>
  </section>


  <footer class="text-center p-7 text-xs text-gray-500">
    &copy; <span id="year"></span> Tanmoy Das &mdash; Portfolio. <a href="mailto:tanmoydas202231@gmail.com" class="underline hover:text-cyan-400">Contact</a>
  </footer>
  <script>
    // Fade-in animation on scroll
    function revealOnScroll() {
      document.querySelectorAll('.fade-in').forEach(section => {
        const rect = section.getBoundingClientRect();
        if (rect.top < window.innerHeight - 40) section.classList.add('visible');
      });
    }
    window.addEventListener('scroll', revealOnScroll);
    window.addEventListener('DOMContentLoaded', () => {
      document.getElementById('year').textContent = new Date().getFullYear();
      revealOnScroll();

      // Lucide icons for social links
      lucide.createIcons();

      // Dropdown menu open/close on click
      const btn = document.getElementById('blogMenuBtn');
      const menu = btn.nextElementSibling;
      btn.addEventListener('click', function(e) {
        e.stopPropagation();
        menu.classList.toggle('hidden');
        menu.classList.toggle('open');
      });
      document.body.addEventListener('click', function() {
        menu.classList.add('hidden');
        menu.classList.remove('open');
      });
      menu.addEventListener('click', function(e) {
        e.stopPropagation();
      });

      // Smooth scroll for blog dropdown
      document.querySelectorAll('.dropdown-menu a').forEach(link => {
        link.addEventListener('click', function(e) {
          const id = this.getAttribute('href').replace('#', '');
          const el = document.getElementById(id);
          if (el) {
            e.preventDefault();
            menu.classList.add('hidden');
            menu.classList.remove('open');
            el.scrollIntoView({ behavior: 'smooth', block: 'start' });
          }
        });
      });

      // --------- Animated Skills Section ---------
      const skills = [
        { icon: "python",     label: "Python",           color: "#ffde57" },
        { icon: "c-plus-plus",label: "C++",              color: "#00599C" },
        { icon: "git-branch", label: "Git",              color: "#F1502F" },
        { icon: "docker",     label: "Docker",           color: "#2496ED" },
        { icon: "layers",     label: "PyTorch",          color: "#EE4C2C" },
        { icon: "braces",     label: "JAX",              color: "#FFB13B" },
        { icon: "camera",     label: "OpenCV",           color: "#5C3EE8" },
        { icon: "function-square",label: "Scikit-Learn", color: "#F7931E" },
        { icon: "brain-circuit", label: "Deep Learning", color: "#22D3EE" },
        { icon: "network",    label: "Machine Learning", color: "#A855F7" },
        { icon: "eye",        label: "Computer Vision",  color: "#8B5CF6" },
        { icon: "rocket",     label: "Reinforcement Learning", color: "#60A5FA" },
        { icon: "language",   label: "NLP",              color: "#A3E635" },
        { icon: "file-type",  label: "LaTeX",            color: "#6366F1" },
      ];
      const container = document.getElementById('skills-list');
      skills.forEach((skill, i) => {
        const card = document.createElement('div');
        card.className = "flex flex-col items-center bg-gray-800 rounded-2xl shadow p-4 hover:scale-105 transition-all duration-300 opacity-0 translate-y-5";
        card.style.animation = `skill-pop 0.7s cubic-bezier(.33,1.53,.52,1) forwards`;
        card.style.animationDelay = `${i * 120}ms`;

        const iconDiv = document.createElement('div');
        iconDiv.className = "mb-2";
        iconDiv.innerHTML = `<i data-lucide="${skill.icon}" style="color: ${skill.color}; width:2.2rem;height:2.2rem;"></i>`;
        card.appendChild(iconDiv);

        const label = document.createElement('div');
        label.className = "text-sm font-medium mt-1 text-gray-100";
        label.textContent = skill.label;
        card.appendChild(label);

        container.appendChild(card);
      });
      lucide.createIcons();

      // Animate in on scroll
      function animateSkills() {
        const section = document.getElementById('skills');
        if (section.getBoundingClientRect().top < window.innerHeight - 60) {
          Array.from(container.children).forEach(card => {
            card.classList.add('animate-in');
          });
        }
      }
      window.addEventListener('scroll', animateSkills);
      animateSkills();
    });
  </script>
<script>
// Slower and smooth code rain background
const canvas = document.getElementById('codeRain');
const ctx = canvas.getContext('2d');
let width, height, columns, drops, fontSize, lastDraw = 0;
const codeChars = "01<>{}[]();=+-*/&|^%$#@!";

// Slower speed: smaller = slower (e.g. 0.7 is slow, 1.0 is default, 1.5 is fast)
const RAIN_SPEED = 0.6;  

function resizeCanvas() {
  width = window.innerWidth;
  height = window.innerHeight;
  canvas.width = width;
  canvas.height = height;
  fontSize = Math.max(14, Math.min(24, width / 80));
  columns = Math.floor(width / fontSize);
  // Use float for smooth slow fall
  drops = Array(columns).fill(1 + Math.random() * 10);
}
window.addEventListener('resize', resizeCanvas);

function draw(now = 0) {
  // Throttle frame rate for extra smoothness (about 40 FPS)
  if (now - lastDraw < 25) { requestAnimationFrame(draw); return; }
  lastDraw = now;
  ctx.fillStyle = "rgba(24,24,27,0.18)";
  ctx.fillRect(0, 0, width, height);

  ctx.font = fontSize + "px 'Fira Mono', 'Consolas', monospace";
  ctx.fillStyle = "#22d3eeCC";

  for (let i = 0; i < columns; i++) {
    const char = codeChars[Math.floor(Math.random() * codeChars.length)];
    ctx.fillText(char, i * fontSize, drops[i] * fontSize);

    // Drops increment slower
    if (drops[i] * fontSize > height && Math.random() > 0.975) drops[i] = 0;
    drops[i] += RAIN_SPEED;
  }
  requestAnimationFrame(draw);
}
resizeCanvas();
draw();
</script>
<script>
window.addEventListener('DOMContentLoaded', function() {
  const blogDropdown = document.getElementById('blogDropdown');
  const btn = document.getElementById('blogMenuBtn');
  const menu = blogDropdown;

  // Build the dropdown menu dynamically
  function buildBlogDropdown() {
    blogDropdown.innerHTML = '';
    // Find all articles INSIDE #blog that have id and data-title
    document.querySelectorAll('#blog article[id][data-title]').forEach(post => {
      const li = document.createElement('li');
      const a = document.createElement('a');
      a.href = `#${post.id}`;
      a.textContent = post.getAttribute('data-title');
      a.className = "block px-4 py-2 text-sm hover:bg-cyan-900/20 transition";
      li.appendChild(a);
      blogDropdown.appendChild(li);

      // Attach smooth scroll handler
      a.addEventListener('click', function(e) {
        const id = this.getAttribute('href').replace('#', '');
        const el = document.getElementById(id);
        if (el) {
          e.preventDefault();
          blogDropdown.classList.add('hidden');
          blogDropdown.classList.remove('open');
          el.scrollIntoView({ behavior: 'smooth', block: 'start' });
        }
      });
    });
  }

  buildBlogDropdown();

  // Open/close dropdown logic
  btn.addEventListener('click', function(e) {
    e.stopPropagation();
    menu.classList.toggle('hidden');
    menu.classList.toggle('open');
  });
  document.body.addEventListener('click', function() {
    menu.classList.add('hidden');
    menu.classList.remove('open');
  });
  menu.addEventListener('click', function(e) {
    e.stopPropagation();
  });
});
</script>





</body>
</html>
